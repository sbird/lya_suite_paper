% \documentclass[fleqn,usenatbib]{mnras}
\documentclass[a4paper,11pt]{article}
% \pdfoutput=1
\usepackage{amsmath, amssymb}

\usepackage{jcappub}
\usepackage{newtxtext,newtxmath}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}
% \usepackage{amssymb}
% Allow "Thomas van Noord" and alike to be sorted by "N" etc. in the bibliography.
% Write the name in the bibliography as "\VAN{Noord}{Van}{van} Noord, Thomas"
\DeclareRobustCommand{\VAN}[3]{#2}
\let\VANthebibliography\thebibliography
\def\thebibliography{\DeclareRobustCommand{\VAN}[3]{##3}\VANthebibliography}

% martin comment function
\newcommand{\maf}[1]{{\textcolor{red}{[{\bf MAF}: #1]}}}
% mingfeng comment function
\newcommand{\mfh}[1]{{\textcolor{green}{[{\bf MFH}: #1]}}}
% simeon comment function
\newcommand{\spb}[1]{{\textcolor{magenta}{[{\bf SPB}: #1]}}}

% ming-feng emulator commands
\newcommand{\mfemu}{\texttt{MFEmulator}}     % i made the acronym, but not used a lot
\newcommand{\Data}{\mathcal{D}}
\newcommand{\gp}{\textsc{gp}}
% \newcommand{\normal}{\mathcal{N}}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\thetavec}{\boldsymbol{\theta}}  % input parameters
% \newcommand{\zvec}{\boldsymbol{z}}
% \newcommand{\outputFunction}{Z}
\newcommand{\outputVector}{\zvec}            % output response
\newcommand{\outputVectorModel}{\zvec_\mathrm{model}}
\newcommand{\outputVectorObs}{\zvec_\mathrm{obs}}
\newcommand{\muvec}{\boldsymbol{\mu}}        % GP mean vector
\newcommand{\Kvec}{\boldsymbol{\mathrm{K}}}  % covariance matrix
\newcommand{\kvec}{\boldsymbol{k}}           % covariance vector
\newcommand{\Lya}{Lyman-$\alpha$}
\newcommand{\astrid}{\texttt{ASTRID}}
\newcommand{\nat}{Nature}

\newcommand{\uniform}{\mathcal{U}}

\newcommand{\apjs}{ApJ Supplement}
\newcommand{\apj}{ApJ}
\newcommand{\apjl}{ApJL}

\newcommand{\aap}{AAP}
\newcommand{\mnras}{MNRAS}
\newcommand{\prd}{PRD}
\newcommand{\prl}{PRL}
\newcommand{\gadget}{{\small GADGET}}
\newcommand{\mpgadget}{{\small MP-GADGET}}

\newcommand{\km}{k_{max}}

\newcommand{\vect}[1]
  {\mbox{\boldmath ${#1}$}}
\newcommand{\matr}[1]
  {\mbox{\bf \sf{#1}}}
\newcommand{\eq}[1]
  {Eq.~(\ref{equation:#1})}
\newcommand{\eqs}[1]
  {Eqs~(\ref{equation:#1})}
\newcommand{\sect}[1]
  {section~\ref{section:#1}}
\newcommand{\sects}[1]
  {sections~\ref{section:#1}}
\newcommand{\tabl}[1]
  {{\mbox Table~\ref{table:#1}}}
\newcommand{\tabls}[1]
  {{\mbox Tables~\ref{table:#1}}}
\newcommand{\fig}[1]
  {Fig.~\ref{Figure:#1}}
\newcommand{\figs}[1]
  {Figs.~\ref{Figure:#1}}
\newcommand{\sourcesection}[1]{\noindent {\em{#1}} ---}

\def\jcap{JCAP}        % Journal of Cosmology and Astro-Particle Physics

\newcommand{\Msun}{\, h^{-1} M_\odot}
\newcommand{\Zsun}{Z_\odot}
\newcommand{\NHunit}{cm$^{-2}$}
\newcommand{\sLLS}{\sigma_\mathrm{LLS}}
\newcommand{\Mpc}{\,\mathrm{Mpc}}
\newcommand{\Mpch}{\, h^{-1} \mathrm{Mpc}}
\newcommand{\kpch}{\, h^{-1}\mathrm{kpc}}
\newcommand{\hMpc}{\, h \mathrm{Mpc}^{-1}}
\newcommand{\kms}{km~s$^{-1}$}
\newcommand{\NHI}{N_\mathrm{HI}}

\newcommand{\edit}[1]{#1}

%opening
\title{A New Suite of Lyman-$\alpha$ Forest Simulations for Cosmology}

\author[a]{Simeon Bird,\note{Corresponding author}}
\affiliation[a]{Department of Physics \& Astronomy, University of California  Riverside,\\900 University Avenue, Riverside, CA 92521, USA}
\author[a]{Martin Fernandez,}
\author[a]{Ming-Feng Ho,}
\author[a]{Mahdi Qezlou,}
\author[a]{Reza Monadi,}
\author[b]{Others: Yueying, Tiziana, Nianyi, Rupert?}
\emailAdd{sbird@ucr.edu}
% \emailAdd{mfern027@ucr.edu}

\abstract{
We present a new suite of $43$ simulations of the Lyman-$\alpha$ forest, spanning a $9$-dimensional parameter space, including $4$ cosmological parameters and $5$ astrophysical/thermal parameters. These simulations advance on earlier simulations suites by larger particle loads, by incorporating new physical models for hydrogen and helium reionization, and by self-consistently incorporating a model for AGN feedback. Parameters are chosen based on a Latin hypercube design and a Gaussian process is used to interpolate to arbitrary parameter combinations. Our simulation suite will be used to interpret existing Lyman-$\alpha$ forest 1D flux power spectra from SDSS and future DESI data releases.
}

\begin{document}

\maketitle

\section{Introduction}

%Introduce the problem. Cite the previous simulation suites for the Lyman alpha forest. The purpose of a simulation suite is to compare to observational measurements. The main output of our suite is a set of medium resolution artificial flux power spectra, from which the flux power spectrum may be generated. In this paper we describe the simulation suite we have run and defer description of the likelihood function to upcoming work.

% Paragraph: the Lyman alpha forest is a classic probe of cosmology.
% Power comes from small scales. Small scales require simulations.
The distribution of neutral hydrogen in the Universe, as traced by \Lya~forest absorption in quasars, is a classic probe of cosmology \citep{Croft:1998}. The power of the \Lya~forest lies in its ability to probe small scales at $z = 2-5$ in a way which is minimally sensitive to galaxy physics. Realising this potential requires cosmological simulations, which are the only way to model the non-linear evolution of the gas and dark matter with sufficient fidelity. The Lyman-$\alpha$ forest has been used to constrain cosmological parameters and make constraints on total neutrino mass ($\sum m_\nu < 0.11$ eV when combined with the cosmic microwave background) \citep{2004MNRAS.354..684V, McDonald:2005pk, Viel:2006, 2005PhRvD..71j3515S, 2006JCAP...10..014S, 2020JCAP...04..038P}, measure the expansion rate (via baryon acoustic oscillations) at $z \sim 2.4$ \cite{Slosar:2011, Bautista:2017, dSAgathe:2019}, test alternatives to cold dark matter \citep{2005PhRvD..71f3534V,  Viel:2013wdm, Irsic:2017pk, Garzilli:2021, 2021PhRvL.126g1302R} and constrain the thermal history of the Universe and thus reionization \citep{2008MNRAS.386.1131B,2014MNRAS.438.2499B, 2016MNRAS.463.2335N, Boera:2019, Gaikwad:2021, 2021arXiv211100019V}.

%When combined with measurements from the The \Lya~forest already provides the best constraints on the total neutrino mass ($\sum m_\nu < 0.11$ eV) are come from the \Lya~forest.
Despite these successes, the constraining power of the \Lya~forest is currently limited by systematic uncertainty, especially in creating large and accurate enough simulation models and in understanding the spectrograph resolution. Here we address the first, presenting a new suite of simulations large enough to model the \Lya~forest at all probed scales and redshifts. Creating an accurate model for the \Lya~forest requires the ability to probe the Jeans scales of the collapsing gas and thus a mean interparticle spacing of $\sim 39$ kpc/h \cite{Borde:2014}. Conversely, the box size required to have a handle on cosmic variance is $\sim 100$ Mpc/h. Ideally, \Lya~forest simulations thus have a particle load of  $3072^3$, which was previously infeasible. Here we present a suite of simulations and an emulator for the flux power spectrum built upon them. Together they are able to make predictions, accurate at the percent level, for the flux power spectrum which would be output by a simulation within a wide range of cosmological parameters. Using the \mpgadget~code developed for the ASTRID simulation, our largest simulations have a box size of $120$ Mpc/h and $2\times 3072^3$ particles, achieving the desired resolution for the \Lya~forest. In addition, the simulations contain a full hydrodynamic galaxy formation model including stellar and black hole physics. The main output is the \Lya~spectra, of which we have generated $691,200$ from each snapshot, and the derived flux power spectra.

%Prior art: McDonald paper. Borde paper. Pedersen's work and how we differ. Puchwein/Bolton SHERWOOD and SHERWOOD-Relics. Walther.
There have been a variety of previous \Lya~forest simulation suites, each following the state of the art in simulation technology. Ref.~\cite{McDonald:2005pk} used dark matter only simulations convolved with a temperature broadening function. Ref.~\cite{Viel:2006}, which is most similar to our own method, used hydrodynamic simulations with a simplified star formation prescription. Each cosmological parameter was varied individually and a polynomial fit to the changes in the flux power spectrum. This approach was extended by Ref.~\cite{Borde:2014} with larger simulations, necessitated by the more precise dataset available in later SDSS releases. Ref.~\cite{Bird:2019} improved on the polynomial fit by develop Gaussian Process emulator techniques for the \Lya~forest. However, the simulations used were small and did not resolve the forest. Later emulators were developed by Refs.~\cite{Walther:2019} and \cite{Pedersen:2021}. Ref.~\cite{Walther:2019} studied the evolution of the IGM temperature using an emulaor. Ref.~\cite{Pedersen:2021, Pedersen:2022} pursued a complementary approach, building an emulated map between the flux power spectrum and the amplitude and slope of the matter power spectrum at $z\sim 3$. There have also been several large-scale \Lya~simulation projects. The Sherwood simulations \cite{Bolton:2017} had extremely high resolution models of the $z=5$ intergalactic medium, and \cite{Puchwein:2022} ran a suite of simulations, SHERWOOD-RELICS, to model the interaction between the intergalactic medium and hydrogen reionization. SHERWOOD-RELICS used a novel two-step procedure to generate inhomogeneous reionization models. A radiative transfer code was run in post-processing on the output of the simulation, generating a map of ionization times. This map was used to model reionization in a second run of the original simulation, allowing it to capture some reionization feedback effects.

We improve on the state of the art in the simulations performed here. The main improvements come from our larger boxes coupled with a high effective resolution. We double the effective resolution of our emulator by using the multi-fidelity technique from \cite{Ho:2022}. In addition, we perform a large suite of simulations which vary both cosmological and astrophysical parameters simultaneously. Finally, we use a ``full-physics'' galaxy formation model incorporating self-shielding, stellar and AGN feedback and models for patchy hydrogen and helium reionization. Overall, we are able to model the flux power spectrum over a wide range of scales and cosmologies at high (percent-level) accuracy.

%The data: SDSS BOSS DR14. XQ-100. HIRES/MIKE.
%Future data: 3D flux power spectrum, tomography.
Most current \Lya~forest data is summarised by statistics along the line of sight to the quasar. The largest dataset is that from Sloan Digital Sky Survey (SDSS) quasars, most recently SDSS DR14 \cite{Chabanier:2019} and soon the Dark Energy Spectroscopic Instrument (DESI). This is both the dataset with the largest number of quasars and thus the smallest statistical error, and the dataset which probes the largest scales where the cosmological information is greatest. However, SDSS is limited both by low signal to noise and moderate spectral resolution, which does not allow it to probe the thermal cutoff of the intergalactic gas and measure small scales. There are thus independent sets of spectra, observing fewer quasars at higher spectral resolution. These include the XQ-100 survey \cite{Irsic:2017pk, Esposito:2022} at moderate spectral resolution, and the higher resolution KODIAQ/SQUAD \cite{KODIAQ:2022} data, as well as the spectra from HIRES/UVES \cite{Viel:2013wdm, Boera:2019}. In this paper we present a simulation model able to mock scales probed by SDSS DR14 and DESI ($k \lesssim 0.05$ s/km) at the percent level, comparable to the statistical accuracy of these datasets. We will show that we are also able to model smaller scales ($k \lesssim 0.1$) at the ten-percent level required by the statistical error in XQ-100 \cite{KODIAQ:2022}.

\section{Simulations}

Overall, we have performed cosmological hydrodynamic simulations at two resolutions, over a parameter space containing a total of $9$ parameters describing both cosmology and astrophysics. Our lower resolution simulations, of which we have $48$, contain $1536^3$ gas particles, $1536^3$ cold dark matter particles and model a $120$ Mpc/h periodic box with a mean interparticle spacing of $79$ kpc/h. Our $3$ higher resolution simulations contain $2\times 3072^3$ particles and thus a mean interparticle spacing of $39$ kpc/h. These choices are justified in Section~\ref{sec:boxsize}. All simulations were run to $z=2.2$, the lowest redshift at which SDSS measures the \Lya~forest flux power spectrum.

Simulations were run using \mpgadget~\cite{MPGadget2018, Bird:2022}, a massively scalable version of the cosmological structure formation code Gadget-3 \cite{Springel:2005}. The generation of initial conditions is described in Section~\ref{sec:initconds}. Section~\ref{sec:gravity} describes the gravity solver, hydrodynamic solver, and cooling.

Sections~\ref{sec:hydrogen} and ~\ref{sec:helium} describe our models for hydrogen and helium reionization respectively, and how their parameters map to the familiar thermal parameters of the \Lya~forest. We have chosen to vary the parameters of our hydrogen and helium reionization models in order to model uncertainty in the thermal history of the intergalactic medium (IGM).
A wide variety of earlier models instead generate arbitrary thermal histories by scaling the heating rates directly \cite[e.g.~][]{Viel:2006}. Scaling the heating rates allows the greatest possible freedom in the redshift evolution of the thermal histories, but does does not directly impose a physically plausible thermal history, which can sometimes lead to best-fit thermal histories which do not correspond to actual simulations \cite{Walther:2019}, Conversely, Ref.~\cite{Garzilli:2019} argued that the assumption of a power law evolution of the mean temperature with redshift \cite{Viel:2013wdm, Irsic:2017} provides a strong prior, although see Ref.~\cite{Garzilli:2021} where stronger data validated the original thermal evolution. Constraining the parameters of physical reionization models ensures that the redshift evolution of the thermal histories produced are physically plausible and self-consistent, and thus simplifies our inference. This choice is enabled by two advances: first, our simulation boxes are large enough to contain many helium reionization bubbles and second, the thermal history of the IGM is now reasonably well constrained, limiting the variety of models it is necessary to marginalise over.

We use a suite of full physics simulations including star formation, stellar winds and AGN feedback. We use full physics simulations primarily because it allows us to incorporate our AGN feedback model self-consistently into the code, rather than with a post-processing correction. AGN feedback has been shown to influence the \Lya~forest flux power spectrum \cite{Viel:2013, Chabanier:2020}. Full-physics simulations also allow us to self-consistently include the effect of self-shielded gas in the modelling, by producing DLAs in our spectral code and removing them, as in the observational analysis. We stress that these are likely small effects and we do not wish to imply that quick \Lya~models are inadequate for current data. However, with current simulation codes the speed difference between the quick \Lya~and full physics simulations is only $\sim 30\%$, and so the cost is relatively small. Furthermore, using full physics simulations allows our suite to be used for other applications in future.

Our galaxy formation model parameters generally follow those used in the \astrid~simulation, as detailed in Refs.~\cite{Bird:2022, Ni:2021}. Here we summarise the main features of the model, and refer the interested reader to \cite{Bird:2022} for more details. Readers familiar with \astrid~should refer to Table~\ref{tab:paramchanges}, which summarises the differences in the galaxy formation model. We describe the star formation and stellar wind model in Section~\ref{sec:stellar}, and the black hole and AGN feedback model in Section~\ref{sec:agn}.

\begin{table*}
\begin{centering}
  \begin{tabular}{lll}
  \hline
  Parameter & New Value & \astrid~Value \\
    \hline
SPH density kernel  & Cubic & Quintic \\
Minimum wind velocity $v_w$ & $100$ km/s & $0$ \\
Temperature at HI reionization & $15000$ K & $0$ K \\
Stars per gas particle & $1$ & $4$ \\
Metal return from stars & Disabled & Enabled\\
Metal line cooling & Disabled & Enabled. \\
    \hline
  \end{tabular}
  \caption{Summary of changes and simplifications in the galaxy formation model from the \astrid~simulation.}
  \label{tab:paramchanges}
  \end{centering}
\end{table*}

%The initial conditions include separate transfer functions for baryons and cold dark matter. The initial distribution of cold dark matter particles is a grid, and the initial distribution of baryons is a Lagrangian glass, as recommended by \cite{Bird:2020} to reduce particle transients. First-order Lagrangian perturbation theory \citep{Zeldovich:1970, Crocce:2006} is used to initialise particle positions and velocities. Second-order terms are not included as they are difficult to model when the initial transfer functions for baryons and cold dark matter are different. Radiation density is included in the cosmological background evolution.
%, a $10\%$ contribution to the Hubble expansion at $z=100$ that affects the total integrated growth rate at the $10\%$ level by $z=10$.

\subsection{Initial Conditions}
\label{sec:initconds}

We generate initial condition for our simulations as in Ref.~\cite{Bird:2020}. We use separate transfer functions for gas and cold dark matter particles, as generated by CLASS \cite{CLASS}. Velocities are initialised using the respective velocity transfer functions, so that the variation in halo gas fraction from dark matter-baryon relative velocities are automatically included in the simulation. Radiation is included in the cosmological background evolution. Simulations are initialised at $z=99$. Cold dark matter is initialised on a regular grid and gas particles are initialised using a force-free Lagrangian glass.

Our emulator is designed to constrain cosmological parameters and so we perform simulations varying cosmological parameters in the initial conditions. Specifically, we define the primordial matter power spectrum as:
\begin{equation}
 P(k) = A_P \left(\frac{k}{ 0.78 \mathrm{h/Mpc}}\right)^{n_P-1}\,.
 \label{eq:pk}
\end{equation}
Here $n_P$ is the spectral index. $A_p$ is the amplitude of perturbations at $k = 0.78$ h/Mpc, chosen to be in the middle of the range probed by the \Lya~forest and thus reduce artificial correlation between $n_P$ and $A_P$ \cite{Bird:2019}. We vary $A_P$ in the range $1.2 \times 10^{-9}$ and $2.6 \times 10^{-9}$, chosen the range of $A_P$ simulated to include the posterior constraint from Planck on larger scales \cite{Planck:2018}.
$n_P$ is the spectral index measured on small scales, which we simulate between $0.8$ and $0.995$. Note that in extended models with a scale-dependence of the spectral index (a ``running''), this need not have the same value as the spectral index measured by Ref.~\cite{Planck:2018}.

We also include free parameters for the growth rate, $\Omega_0 h^2$, and Hubble parameter, $h$. We vary $h$ over the range $0.65$ - $0.75$ and $\Omega_0 h^2$ between $0.14$ and $0.146$. The growth rate $\Omega_0 h^2$ has a moderate effect on the \Lya~forest, but is generally measured better by other probes. As our simulation box is set up using kpc/h units, the Hubble parameter $h$ does not affect the gravitational evolution of the code. The cooling rates are computed in physical units, and so in principle the thermal history parameters may interact with $h$. However, as we will show in Section~\ref{sec:singleparams}, the residual dependency is small for the range of $h$ we consider. Nevertheless, we chose to include $h$ in our emulator. Including $h$ allows our simulations to be re-used as part of future emulators targetting, for example, the 3D power spectrum, where the position of the BAO peak depends on $h$.

A secondary technical reason for including $h$ is to avoid the Gaussian process fit being impacted by cosmic variance.
Varying $h$ while fixing $\Omega_0 h^2$ also varies $\Omega_0$. The conversion between comoving kpc/h and km/s is
\begin{equation}
 1 \mathrm{km/s} =  100 a (\Omega_0 /a^3 + \Omega_\Lambda )^{1/2} \mathrm{kpc/h}\,.
\end{equation}
Changing $h$ moves the simulation box's Fourier modes relative to the bins of the observed data, and so allows the emulator to see the effect of cosmic variance. In retrospect the benefit of this choice is small as our large boxes mean cosmic variance is minimal. However, our Latin Hypercube experimental design (see Section~\ref{sec:latinhypercube}) allows us to vary parameters with a small effect on the flux power spectrum at low computational cost.

We do not include a parameter for massive neutrinos. Neutrinos are massless and included in the radiation, as the effect of massive neutrinos on these scales is completely degenerate with the amplitude of the initial perturbations, $A_P$ \cite{Pedersen:2020}.
Schematically, neutrino mass constraints come from measuring different power spectrum amplitudes on CMB and \Lya~scales. We do not vary $\Omega_b$ as it is degenerate with the ionization fraction of the gas and thus the mean optical depth $\tau$.

\subsection{Gravity, Hydrodynamics and Cooling}
\label{sec:gravity}

%The gravity solver in MP-Gadget uses the same basic algorithms as Gadget-3.
We use the same gravity solver described in Ref.~\cite{Bird:2022} and references therein. Long range gravitational forces are computed in Fourier space using a particle-mesh algorithm. Short-range forces, below the resolution of the particle grid, are computed using a hierarchical multipole expansion of the gravitational field, leading to a uniformly high force resolution throughout the computational volume. The default accuracy of the split between short and long range forces has been increased and the force accuracy of \mpgadget~is better than 1\% as measured against an exact N-body solver.
%able to reproduce the matter power spectrum output by PKDGRAV3 to $<1\%$ \cite{Schneider:2016}.

We adopt the pressure-entropy formulation of smoothed particle hydrodynamics (pSPH) to solve the Euler equations \citep{Hopkins:2013,Read:2010} as implemented by \cite{Feng:2014}. %The density estimator uses a quintic density kernel to reduce noise in SPH density and gradient estimation \citep{2012JCoPh.231..759P}.
The SPH density kernel uses a cubic polynomial, rather than the quintic kernel from \astrid, as the reduced number of neighbours improves resolution in the \Lya~forest. This comes at the cost of increased noise in dense regions, but at forest densities this does not affect the dynamics \cite{Bird:2013}.
Gas is allowed to cool radiatively following \citep{Katz:1996}.
We have used the updated cooling coefficients summarised in \cite{Bolton:2017}, the recombination rates from \cite{Verner:1996} and collisional ionization rates from \cite{Voronov:1997}. Self-shielding of neutral hydrogen is included following the fitting function of \cite{Rahmati:2013}.
The UV background used is the ``optically thin'' variant from Ref.~\cite{FG2020}. There is also a variant which corrects for the average effect of partial reionization on the gas temperature; we do not use this as we instead include explicit models for patchy reionization.

\subsection{Hydrogen Reionization}
\label{sec:hydrogen}

We model patchy reionization with a spatially varying ultra-violet background using a semi-analytic method \cite{Battaglia:2013} which pre-computes a reionization redshift, on a grid with cells $1$ Mpc/h, using FASTPM \cite{FASTPM}. The redshift of reionization, $z_{HI}$, is defined as the redshift at which $50\%$ of the simulation volume has reionized. In general, higher initial overdensities reionize earlier. We simulate $z_{HI}$ over the range $6.5 - 8$. Our use of a patchy reionization model means that we naturally include lower redshift effects of reionization on the \Lya~forest \citep{Montero:2019}

For gas particles in a region which has not yet reionized, the photon background is set to zero and the gas remains neutral. Once the reionization redshift has passed, the particle's ionization and thermal states evolve in ionization equilibrium with the external UV background. Newly in these simulations, we include a temperature boost to each gas particle as it passes the reionization redshift to account for the (subgrid) heating effect of ionization fronts.
Each gas particle on reionization has its temperature boosted to $15,000$K.
Ref.~\citep{DAloisio:2019} found a temperature boost of $\sim 20,000$K in their radiative transfer simulations. However, our simulation is much lower resolution and has much longer timesteps, suggesting that we should expect a certain amount of subgrid cooling before any given particle in our simulation box becomes active. Furthermore, we found that a temperature boost of $20,000$ K led to generally higher IGM temperatures when compared to observations $z\sim 6$, at least for the relatively low reionization redshifts preferred by current mean free path observations \cite{Cain:2021}.

The reionization temperature boost means that $z_{HI}$ affects the thermal history of the IGM. After reionization the UV background is not sufficiently intense to preserve a thermal equilibrium and so the gas cools. The reionization parameter, $z_{HI}$, thus controls the IGM temperature before helium reionization starts at at $z \gtrsim 4$. Note that as long as $z_{HI} > 5.8$, the current highest redshift IGM temperature measurement \cite{Gaikwad:2020}, $z_{HI}$ is observationally degenerate with the size of the reionization temperature boost. Our ultimate constraints on the reionization redshift should thus be understood to be conditional on a boost of $15,000$ K.

%We do not boost the gas temperature to account for the passage of ionization fronts \citep{2019ApJ...874..154D}.

\subsection{Helium Reionization}
\label{sec:helium}

We include a model for spatially inhomogeneous helium reionization following \cite{UptonSanderbeck:2020}. Reionized bubbles are placed around randomly chosen halos with mass $10^{13} \geq M_{\rm halo}\geq 10^{12}$M$_{\odot}$, which could host a quasar. Bubbles are $20$ Mpc/h in radius, matching the mean bubble size found in radiative transfer simulations \citep{McQuinn:2009}. Inside this bubble a quasar radiation field is assumed with an effective spectral index of $- \alpha_q$, which we vary in our simulation suite over the range $\alpha_q  = 1.6 - 2.5$. During the reionization timestep gas particles in a bubble are abruptly heated and marked as ionized. Should bubbles overlap, only particles not already marked as ionized are heated. Bubbles are placed until the total ionized gas mass in the box reaches
a pre-computed ionization fraction. We assume a linear ionization history between the initial redshift $z_{Hei}$ and the final redshift $z_{Hef}$. Following measurements of the optical depth in the Helium \Lya~forest \cite{Worseck:2019}, we simulate $z_{Hei} = 3.5 -  4.1$ and $z_{Hef} = 2.6 - 3.2$.

Our $120$ Mpc/h box simulations contain $\sim 50$ reionization bubbles and so our model includes the patchiness of helium reionization and the resulting fluctuations in temperature, ionization state, and pressure smoothing. A consequence is that there is no unique temperature-density relation in our simulations, but a range of temperature-density relations depending on the time at which a given part of the simulation reionized. Our three free parameters allow us to generate a wide range of thermal histories, as shown in Figure~\ref{fig:meanigmtempdens}. The quasar spectral index, $\alpha_q$ controls the level of heating during helium reionization and thus the peak IGM temperature. Higher values of $\alpha_q$ lead to lower peak temperatures.

%$z_{Hei}$ and $z_{Hef}$ are the start and end redshifts, respectively, of helium reionization. $z_{Hi}$ is the midpoint redshift of hydrogen reionization. $\alpha_q$ is the quasar emissivity spectral index, which controls the peak IGM temperature at the midpoint of helium reionization.

\begin{table*}
\begin{centering}
  \begin{tabular}{llll}
  \hline
  Parameter & Minimum & Maximum & Description \\
    \hline
    $n_P$  &  $0.8$  & $0.995$ & Scalar spectral index \\
    $A_P$  &  $2.2 \times 10^{-9}$  & $2.6 \times 10^{-9}$ & Power amplitude at $k = 0.78$ h/Mpc \\
    $h$    & $0.65$  & $0.75$ & Hubble parameter \\
    $\Omega_0 h^2$ & $0.14$ & $0.146$ & Total matter density \\
    $z_{Hei}$      & $3.5$  & $4.1$  & Start redshift of HeII reionization \\
    $z_{Hef}$      & $2.6$  & $3.2$  & End redshift of HeII reionization \\
    $\alpha_q$     & $1.6$  & $2.5$ & Quasar spectral index during HeII reionization  \\
    $z_{Hi}$        & $6.5$ & $8$   & Median redshift of HI reionization \\
    $\epsilon_{AGN}$ & $0.03$ & $0.07$ & Thermal efficiency of black hole feedback \\
    \hline
  \end{tabular}
  \caption{Summary of varied emulator parameters, together with the ranges covered by the emulator. We vary a total of $9$ parameters: $4$ for cosmology, $3$ for the helium reionization model, $1$ for the hydrogen reionization model and $1$ for the strength of AGN feedback.}
  \label{tab:emulatorparams}
  \end{centering}
\end{table*}

\subsection{Star Formation and Stellar Feedback}
\label{sec:stellar}

Stars form on an effective equation of state in dense gas, following \cite{Springel:2003}. Stars are formed with the same mass as a gas particle, so that gas particles are converted directly to stars. Note that \astrid~formed stars with $1/4$ of the mass of the gas particle. This increases the number of particles in dense regions which have little effect on the \Lya~forest, and so for our simulation suite simply increases computational cost.

We disable metal return from stars, as evaluating this model can be computationally expensive, and we are building an emulator for the neutral hydrogen of the \Lya~forest. We also disable metal cooling, which Ref.~\cite{Viel:2013} showed has a small effect on the \Lya~forest flux power spectrum. Similarly, we do not include the (metallicity dependent) correction to the high redshift star formation rate due to the formation of molecular hydrogen implemented in \astrid, which has a very small effect for $z < 6$.

A stellar wind feedback model is included following Ref.~\citep{Okamoto:2010} and Ref.~\cite{Bird:2022}. Wind speeds are proportional to the local one dimensional dark matter velocity dispersion $\sigma_\mathrm{DM}$:
\begin{equation}
v_w = \kappa_w \sigma_\mathrm{DM} \,,
\end{equation}
where $v_w$ is the wind speed. $\kappa_w$ is a dimensionless parameter, which we take to be $3.7$ following \cite{Vogelsberger:2013}. We have mildly altered the model from \cite{Bird:2022} by implementing a minimum wind velocity, $v_w \geq 100$ km/s, in order to improve convergence with resolution.

Winds are sourced by newly formed star particles, which randomly pick gas particles from within their SPH smoothing length to become wind particles. The total mass loading is $(v_w/ 350 \mathrm{km/s})^{-2}$ where $350$ km/s is in physical units. Particles recouple when their surrounding density drops by a factor of $10$, or after $60$ Myr.\footnote{In Ref.~\cite{Bird:2022} we had a subdominant recoupling condition: gas would recouple after $20 \mathrm{kpc} / v_w$. In practice this affected only a small fraction of the wind, as for a typical star forming halo with a virial velocity of $200$ km/s the recoupling time was $100$ Myr, and gas always recoupled after $60$ Myr. We have thus removed this condition for model simplicity.} Particles in the wind cool, but do not experience or produce pressure forces, nor may they be accreted onto a black hole. However, to enhance the stability of the SPH density estimates, they are included when computing SPH smoothing lengths.

We conducted an early test emulator using small boxes where the dimensionless supernova wind velocity, $\kappa_w$, was a free parameter of the model. However, we found that this free parameter was essentially unconstrained by the \Lya~forest data and so opted not to vary it in the full emulator run. Ref.~\cite{Bolton:2017} showed that supernova winds increased the \Lya~flux power on large scales, $k < 10^{-2}$ s/km, at $z < 3$, by around $10\%$, due to the presence of additional high column density systems\footnote{Ref.~\cite{Viel:2013} found that the \Lya~flux power spectrum was increased only for $ k > 0.04$ s/km (scales smaller than those measured by BOSS), but their simulations did not include self-shielding and so did not contain high column density absorbers.}. Our supernova simulation model parameters have been chosen to match the observed galaxy stellar mass function and thus the distribution of high column density absorbers. We remove high column density systems from our simulated spectra to match the observational procedure, and thus changes to the supernova wind model do not affect the \Lya~flux power spectrum.

\subsection{Black Holes and AGN Feedback}
\label{sec:agn}

Our simulations include super-massive black hole (SMBH) seeding, growth and feedback following Ref.~\cite{Ni:2022}, itself based on \cite{Feng:2016,SDH2005,DSH2005}. Compared to \astrid, we have adapted some of the thresholds to our lower resolution simulations.

SMBH particles are seeded by converting the densest gas particle found in a halo. To be eligible for seeding, a halo must have total mass greater than $5\times 10^{10}\,h^{-1}M_\odot$ and stellar mass greater than $2 \times 10^9 h^{-1} M_\odot$. The SMBH seed mass is $5 \times 10^{-5} h^{-1} M_\odot$. The initial dynamic mass of the SMBH, which keeps the dynamical friction model stable for BH seeds, is set as $10^{8} h^{-1} M_\odot$. For comparison, the gas particle mass is $5 \times 10^6 h^{-1} M_\odot$ and the CDM mass is $ 3 \times 10^7 h^{-1} M_\odot$. SMBH are thus seeded only in well-resolved halos with (on average) $> 1400$ CDM particles and $>400$ star particles.

We implement a model for dynamical friction following Ref.~\citep{Chen:2021}. This ensures that SMBHs are kept close to the centers of their halos, and replaces the earlier manual repositioning. Dynamical friction is an artificial force modelling unresolved small-scale interactions between the SMBH and nearby stars. These interactions transfer momentum from the SMBH to individual stars in the surrounding star clusters. We include dynamical friction from star and CDM particles, but in practice the star particles strongly dominate \cite{Chen:2021}.

BHs are allowed to grow by accreting mass from nearby gas particles. Gas accretes following the Bondi-Hoyle-Lyttleton formula, applied to the smoothed properties of the gas particles within the SPH kernel of the BH:
\begin{equation}
\label{equation:Bondi}
    \dot{M}_{\rm B} = \frac{4 \pi \alpha G^2 M_{\rm BH}^2 \rho}{(c^2_s+v_{\rm rel}^2)^{3/2}}
\end{equation}
$c_s$ and $\rho$ are the local sound speed and density of gas, $v_{\rm rel}$ is the relative velocity of the BH with respect to the nearby gas and $\alpha = 100$ is a dimensionless fudge parameter to account for the underestimation of the accretion rate due to the unresolved cold and hot phase of the subgrid interstellar medium nearby.
Note that hydrodynamically decoupled wind particles are not included in the density calculation of Eq.~\ref{equation:Bondi}. The accretion rate is capped at $2$ times the Eddington accretion rate.
%Numerically, the physical BH mass, $\mbh$, grows continuously with time, while we separately track the BH dynamic mass by stochastic accretion of nearby gas particles with a probability that statistically satisfies mass conservation. Given that $M_{\rm dyn}$ is temporarily boosted (and initially fixed) for the new-born BH particles for gravity and dynamical friction calculation, we use a separate mass tracer $M_{\rm trace}$ to perform gas accretion when $\mbh < M_{\rm dyn,seed}$.
%This term is initialized as the parent particle mass that spawns the BH, and traces $\mbh$ with stochastic gas accretion until $\mbh >= M_{\rm dyn,seed}$. After that, $M_{\rm dyn}$ grows following $\mbh$ by swallowing gas.
%To ensure stable accretion, the timestep of the BH particle is set not by the acceleration dynamics, but by being $2$ times longer than the smallest timestep found amongst the gas particles within its density kernel.

AGN thermal feedback energy is implemented by depositing a fraction, $\epsilon_{AGN}$ of the available radiative energy for the AGN into the gas. We assume an accretion disk with a mass-to-light conversion efficiency of $0.1$, so that the AGN thermal energy is \cite{Shakura:1973}
\begin{equation}
\label{equation:Lbol}
    E_\mathrm{AGN} = \frac{\epsilon_{AGN}}{10} \dot{M}_{\rm BH} c^2\,.
\end{equation}
The efficiency of the thermal feedback, $\epsilon_{AGN}$ is a free parameter of our emulator and simulate it in the range $0.03 - 0.07$.

$E_\mathrm{AGN}$ is deposited isotropically to particles within $3$ kpc/h. We use $3$ kpc/h instead of the SPH smoothing radius in an attempt to improve convergence with resolution, as this is roughly the smoothing length at the resolution of \astrid. However, in practice this choice has no measurable effect on the \Lya~forest. The AGN feedback modifies the cooling time of the star-forming gas, allowing it to cool on the cooling timescale rather than the longer relaxation timescale, and thus moderately increases the star formation rate.

In our purely thermal AGN feedback model, AGN feedback does not remove gas from a halo and thus does not suppress the matter power spectrum. At $z > 2$ the matter power spectrum suppression is fairly mild in AGN feedback models, as there are few SMBHs in the low accretion regime necessary to induce kinetic mode feedback. While the effect of AGN feedback on weak lensing is driven by the removal of gas from massive halos \cite[e.g.~][]{Giri:2021}, the \Lya~forest is also directly sensitive to the gas temperature around halos, and so may be affected by purely thermal feedback.

Our emulator design also allows us to measure parameter degeneracies between AGN feedback and cosmological parameters. Ref~\cite{Schneider:2015} showed a degeneracy between AGN feedback and the fraction of matter in baryons, $\Omega_b / \Omega_0$. However, since the \Lya~forest may be sensitive to the gas temperature, there may also be a degeneracy with the number density of actively radiating SMBHs, which we would be able to detect.

%\cite{Giri:2021} show that the effect is well described by the halo scale at which AGN feedback starts to remove the gas.
%Since the level of AGN feedback present in simulations is currently uncertain, we vary the strength of thermal feedback in our emulator.

\subsection{Generation of Spectra}
\label{sec:spectra}

We generate artificial spectra and compute the flux power spectrum as described in \cite{Bird:2019}. Each simulation generates output snapshots evenly spaced every $\Delta z = 0.2$ between $z = 5.2$ and $z = 2$. Spectra are generated using ``fake\_spectra'' \footnote{\url{https://github.com/sbird/fake_spectra}} \cite{FSFE:2017}.

Our algorithm for generating artificial spectra differs from most other spectral generation codes. Most codes compute the neutral hydrogen density onto a 1D grid of spectral pixels, and then convolve each spectral pixel with the Voigt profile \cite[e.g.~]{Theuns:1998, Chabanier:2022}. Thus for a pixel at position $x(i)$ the density, velocity and temperature $\rho$, $v$ and $T$ are computed in each bin by summing particles with neutral hydrogen density $\rho_i$:
\begin{align}
 \rho(x(j)) &= \Sigma \rho_i \\
 v(x(j)) &= \Sigma_i v_i \rho_i / \rho(x(j)) \\
 T(x(j)) &= \Sigma_i v_i \rho_i / \rho(x(j))\,.
\end{align}
The optical depth is computed by convolution with a Voigt profile:
\begin{align}
 \tau(x(j)) &\propto \Sigma_k \rho(x(k)) \mathcal{V}\left[\frac{(v(k) - v(j))^2}{b(k)^2}\right] \\
 b(j) &= \sqrt{\frac{2 k_B T(j)}{m_P}}\,.
\end{align}
where $b(j)$ is the Doppler width of the line and $\mathcal{V}$ is the Voigt profile.
``Fake\_spectra'' instead skips the intermediate step of creating a density profile and computes the optical depth directly. In effect, each SPH particle is treated as an individual absorber, and the total absorption profile is the sum of the absorption from all particles:
\begin{align}
 \tau(x(j)) &\propto \Sigma_i \rho_i \mathcal{V}\left[\frac{(v(x(j)) - v_i)^2}{b_i^2}\right] \\
\end{align}
This preserves the ionization and velocity gradients inside a spectral pixel more accurately and shows better convergence, especially for dense gas \cite{Bird:2015}.

%We generate $32000$ \Lya~absorption spectra at random positions. To improve emulation performance, the random positions are the same for each simulation. The pixel width is $10$ km/s, finer than either the BOSS or DESI spectrograph. Flux power spectra are generated in h/Mpc units, with the natural Fourier bins of the box, and transformed to velocity units after emulation. The flux power spectrum is generated as average of the 1D Fourier transform along each sightline. We discard spectra with a maximum optical depth $\tau > 10^6$ as containing a DLA. This affects approximately $2\%$ of spectra.

We generate spectra with a pixel width of $10$ km/s, finer than either the BOSS or DESI spectrograph. Flux power spectra are generated in h/Mpc units, with the natural Fourier bins of the box, and transformed to velocity units after emulation. We compute the power spectrum of the flux overdensities, $P_F(k)$ as:
\begin{align}
 \delta_F(x) &= \mathcal{F} / \bar{\mathcal{F}} - 1 \\
 P_F^i(k) &= < \hat{\delta}_F \hat{\delta}_F^* >
\end{align}
The overall flux power spectrum $P_F(k) $ is generated as average of the 1D Fourier transform along each sightline.

Our spectral sample for each simulation snapshot is a regular grid of $480^2$ sightlines, with a mean separation of $250$ kpc/h. We verified explicitly that a grid of $720^2$ sightlines produced a flux power spectrum differing by less than $0.1\%$. We generate three grids, one through each axis of the box. This reduces the sample variance in the flux power spectrum on the largest scales by factor of $3$.

Since our simulations contain a realistic DLA population, we model the effect of masking DLAs using a procedure similar to the observational pipeline \cite{Chabanier:2020}. We first identify spectra with a maximum pixel optical depth $\tau > 10^6$ (corresponding to a column density $\sim 10^{20}$ cm$^{-2}$) as containing a DLA. We then mark the region around this maximum optical depth where $\tau > 2$, chosen to match the threshold of Ref.~\cite{Chabanier:2020}, which masks until the DLA is $20\%$ of the absorption. Absorption in this region is set to the overall mean flux, so that it has $\delta_F = 0$. DLA masking affects approximately $2\%$ of spectra, in agreement with \cite{Rogers:2019}.

We rescale our simulated spectra to match a desired mean optical depth. As in \cite{Bird:2019}, our emulator has the ability to generate flux power spectra for arbitrary input mean optical depth $\tau$. This is achieved by rescaling the spectra in post-processing: no extra simulations are needed. We are thus able to dramatically over-sample the mean optical depth as an input parameter, generating a dense grid of $10$ optical depth samples per redshift per cosmological simulation. As explained in \cite{Bird:2019}, we generate one Gaussian Process emulator for every redshift bin, each emulator taking the mean optical depth at that redshift as an input parameter. We would thus be able to use very general redshift variations of the mean optical depth if supported by observational data.

Based on earlier work and observational data, we specialise our mean flux model to a power law. The amplitude $\tau_0$ and slope $d\tau_0$ of this power law are free parameters, defined relative to the value of $\tau_\mathrm{eff}$ measured by Ref.~\cite{Kim:2007}:
\begin{align}
\tau_\mathrm{Kim}(z) &= 0.0023 \times (1 + z)^{3.65} \\
 \tau_\mathrm{eff}(z) &= \tau_0 \left(\frac{1+z}{4}\right)^{d\tau_0}  \tau_\mathrm{Kim}(z)
 \label{eq:meanflux}
\end{align}
Thus by construction $d\tau_0$ does not affect the $z=3$ flux power spectrum, and $\tau_0 = 1$ and $d\tau_0 = 0$ correspond to Ref.~\cite{Kim:2007}.


% This is done because for any given redshift bin there is a degeneracy between $\tau_0$ and $d\tau_0$. Computing the mean flux in each redshift bin separately breaks this degeneracy and avoids duplicate spectra.


\subsection{Experimental Design}
\label{sec:latinhypercube}

\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{figures/sample_params.pdf}
    \caption{\label{fig:samples}
    Parameter limits for each of the nine parameters varied in the simulation suites.
    Samples at low fidelity (grey crosses) and high fidelity (red circles) are shown.
    }
\end{figure}

% Describe the chosen cosmological parameters. Add a plot as Figure 3 of the multi-fidelity paper. Explain why these parameters are chosen. We use a Latin Hypercube design. Outputs are every $\Delta z=0.2$ from $z=5.4$ to $z=2.0$.

Our emulator includes a total of $10$ parameters at each redshift. One parameter, the mean flux, is generated in post-processing, meaning that we run simulations covering a $9$-dimensional parameter space, summarised in Table~\ref{tab:emulatorparams}.

The low fidelity simulation parameters were selected using either a Latin hypercube sampling scheme, or using Bayesian optimization.
The $48$ low fidelity simulation parameters were selected in the following manner: an initial Latin hypercube sample of $30$ simulations was generated and run, then Bayesian optimization, as described in \cite{Rogers:2019}, was used to select $2$ further simulations.
However, we found that the initial space was not finely sampled enough for Bayesian Optimization to be effective: we thus ran an extra $8$ simulation Latin Hypercube, followed by $2$ more Bayesian optimization samples. Finally, after examination of the simulation showed that the lower range of the $\alpha_q$ parameter was close to the boundary of our simulation space, we generated $6$ samples from a Latin hypercube at a lower range for the $\alpha_q$ parameter.
The final set of low fidelity samples is shown in Figure~\ref{fig:samples}, indicated by the grey crosses, which demonstrates that our simulation sets efficiently cover parameter space.

We generate simulations at specific points in parameter space using a Latin Hypercube design, following the description in \cite{Bird:2019}. Latin Hypercubes are generated at random on a normalised unit cube, and the design which maximises the spread between parameter points is chosen for the final emulator. We ran $30$ simulations in our initial Latin Hypercube design. We supplemented these simulations with $2$ chosen by Bayesian optimisation, as described in \cite{Rogers:2019}. However, we found that the initial space was not finely sampled enough for Bayesian Optimization to be effective: we thus ran an extra $8$ simulation Latin Hypercube, before $3$ more simulations chosen with Bayesian Optimisation. The parameters simulated are shown in Figure~\ref{fig:samples}, which demonstrates that both sets efficiently cover parameter space.

We then performed $3$ simulations at high fidelity, shown by the red circles in Figure~\ref{fig:samples}. The parameters to simulate were selected as suggested in \cite{Ho:2022,Fernandez:2022}, by finding which $n$-simulation subset of the already complete low fidelity simulations produced the most accurate emulator.

Specifically, the high fidelity samples were chosen by training a single-fidelity emulator using all combinations of two low fidelity samples (excluding the aforementioned simulations without mean temperature data) to predict the remaining low fidelity samples for both the flux power and mean temperature \cite{Ho:2022}.
The two low fidelity simulations which produced the most accurate predictions (defined as minimizing the loss, $(pred - true)^2/true^2$) for the combination of the flux power and mean temperature were then run at the higher resolution.
These first two high fidelity samples were selected prior to the low fidelity simulations that were run to expand the $\alpha_q$ parameter.
The final high fidelity sample was chosen using the same method, but conditioned on the previously selected two samples.
Each remaining low fidelity sample was added to the set of two previously selected samples, an emulator was trained using each of these three sample combinations, then the loss for each combination was calculated.
Using both the loss from this method, and the value of $A_p$ for each sample (among the varied parameters, $A_p$ has by far the strongest effect on the amount of computational time the simulation requires to complete), we selected a third sample to run at high fidelity that had low loss and low $A_p$.
This final high fidelity sample was chosen from the full set of low fidelity samples (after the $\alpha_q$ expansion simulations were added). Table~\ref{tab:highfidelity} shows the parameters of our $3$ high fidelity simulations.

\begin{table*}
\begin{centering}
  \begin{tabular}{llll}
  \hline
  Parameter & HF 1 & HF 2 & HF 3\\
    \hline
    $n_P$  &  $0.909$  & $0.914$ & $0.859$ \\
    $A_P$  &  $1.98 \times 10^{-9}$  & $1.32 \times 10^{-9}$ & $1.29 \times 10^{-9}$\\
    $h$    & $0.68$  & $0.74$ & $0.69$\\
    $\Omega_0 h^2$ & $0.1403$ & $0.1415$ & $0.1412$\\
    $z_{Hei}$      & $3.75$  & $3.85$  & $ 3.92$ \\
    $z_{Hef}$      & $3.00$  & $2.65$  & $2.72$\\
    $\alpha_q$     & $2.43$  & $1.575$ & $ 1.87$ \\
    $z_{Hi}$        & $7.6$ & $6.875$   & $7.15 $\\
    $\epsilon_{AGN}$ & $0.045$ & $0.040$ & $ 0.058$\\
    \hline
%    [[0.909475936, 1.98137389e-09, 3.75465601, 3.00952068, 2.43025565, 0.681591829, 0.1403, 7.60269787, 0.0448727377],
%    [0.91375, 1.31666667e-09, 3.85, 2.65,     1.575, 0.741666667, 0.1415, 6.875, 0.04],
%    [0.859013158, 1.29210526e-09, 3.91842105, 2.71842105, 1.87236842, 0.693421053, 0.141184211, 7.15131579, 0.0578947368]]
  \end{tabular}
  \caption{Parameters of the three high fidelity (HF) simulations, performed with $2\times 3072^3$ particles.}
  \label{tab:highfidelity}
  \end{centering}
\end{table*}

\subsection{Multi-Fidelity Emulator}

Finally, we construct from our simulations a multi-fidelity Gaussian Process (GP) emulator following the scheme described in Refs.~\cite{Bird:2019, Fernandez:2022}.
This allows accurate predictions of the simulated output, along with a measure of prediction uncertainty, for arbitrary cosmological parameters within our input set. We first construct an emulator, based on a Gaussian Process, for our low fidelity simulations. We then use the multi-fidelity technique, which allows for a cosmology dependent correction function, to generate a prediction for high fidelity simulations at arbitrary cosmologies.
The multi-fidelity technique allows for simulations with different resolutions to be combined together: low resolution simulations explore parameter space and their low resolution result is corrected by a few high resolution evaluations. The multi-fidelity technique was introduced in astronomy by Ref.~\cite{Ho:2022} and applied to the \Lya~forest in Ref.~\cite{Fernandez:2022}.

The ultimate result is the construction of an emulator which can predict the \Lya~flux power spectrum for arbitrary cosmological parameters at the resolution of the high fidelity simulations. However, instead of the daunting task of performing $\sim 50$ simulations at our high fidelity ($3072^3$ particles), we need only run simulations at our low fidelity and apply a correction function using $3$ high fidelity simulations. Overall, our multi-fidelity emulator is able to make predictions similar to a suite of $\sim 50$ simulations with a mean interparticle spacing of $39$ comoving kpc/h.

Our multi-fidelity emulator is built on Gaussian Processes, using the GPy
package \cite{gpy2014} and EmuKit \cite{2021arXiv211013293P}. If $P_F(\boldsymbol{\theta})$ is the simulated \Lya~forest flux power spectrum as a function of $\boldsymbol{\theta}$, the input parameters to the simulation, then a GP models this output as draws from a distribution
\begin{equation}
    P_F(\boldsymbol{\theta}) \sim GP(\mu(\boldsymbol{\theta}), k(\boldsymbol{\theta}, \boldsymbol{\theta}^{\prime})),
\end{equation}
where $\mu(\boldsymbol{\theta})$ and $k(\boldsymbol{\theta}, \boldsymbol{\theta}^{\prime})$ are the mean and covariance function, respectively.
As in \cite{Fernandez:2022}, we rescale the training samples by the median of the low fidelity spectrum, so that they match the GP prior of a zero mean function. The predictions are then multiplied by this rescaling factor on output. The covariance kernel is the combination of a radial basis function and a linear kernel, following \cite{Fernandez:2022}. The total kernel is
\begin{equation}
        k_\mathrm{RBF}(\boldsymbol{\theta}, \boldsymbol{\theta}'; \sigma_0, \boldsymbol{l}) + k_\mathrm{LIN}(\boldsymbol{\theta}, \boldsymbol{\theta}'; \boldsymbol{\sigma})\\
        = \sigma_0^2 \exp{\left( \sum_{i=1}^{d} -\frac{(\boldsymbol{\theta}_i - {\boldsymbol{\theta}_i}')^2}{2 l_i^2} \right)} +  \sum_{i=1}^{d} \sigma_i^2 \boldsymbol{\theta}_i {\boldsymbol{\theta}_i}',
\end{equation}
where $d$ is the dimensionality of the input parameters.

The multi-fidelity part of the model uses the linear multi-fidelity model Ref.~\citep{10.1093/biomet/87.1.1}. A high fidelity prediction is given by
\begin{equation}
    P_F^{^\mathrm{HF}}(k, z, \boldsymbol{\theta}) = \rho(k, z) \cdot P_F^{^\mathrm{LF}}(k, z, \boldsymbol{\theta}) + \delta(k, z, \boldsymbol{\theta}),
    \label{eq:ko_model}
\end{equation}
where $\rho$ is a scaling parameter, and $\delta(\boldsymbol{\theta})$ is a GP (independent of the LF output). Both $\rho$ and $\delta$ are optimized using the training samples. $\rho$ is a multiplicative correction, and $\delta(\boldsymbol{\theta})$ is an additive correction. Notice that the cosmology dependence comes from $\delta$. In practice we shall see that the cosmology dependence of the resolution correction is fairly small for our simulations, and so the linear multi-fidelity model is a good choice.

The hyperparameters that are learned from the training samples are: variances for the RBF ($\sigma_0^2$) and  linear ($\boldsymbol{\sigma}^2$) kernels, and the lengthscale controlling the smoothness of the RBF kernel, $\boldsymbol{l}$. An independent value is assigned for each dimension $d$ of the input for each of these hyperparameters. Parameters to which the flux power spectrum is more sensitive have a smaller scale. The kernel for $\delta(\boldsymbol{\theta})$ is also the combination of an RBF and a linear kernel. However, all parameters share a single length scale. This simplification was done to improve the training time, and we verified that it did not affect prediction accuracy. With only $3$ high fidelity samples, there is in any case little data to separately optimise the hyperparameters of $\delta(\boldsymbol{\theta})$.

Ref.~\cite{Fernandez:2022} trained a GP for every $k$ bin for every redshift. However, with our increased training set size, we found that training a GP for each $k$ bin led to very large memory usage for the emulator, and substantially slowed down the training and prediction steps. Here we instead train a single GP for each redshift bin, across the full $k$ range. We found that the emulator accuracy was similar for our dataset.

% The code used to generate training samples, train and test single- and multi-fidelity emulators, and perform inference via MCMC is publicly available at: \url{https://github.com/sbird/lya_emulator_full}.

\subsubsection{Leave One Out Errors}

Figure~\ref{fig:fps_error} shows the interpolation accuracy for our emulator. Accuracy is measured using leave-one-out errors. Each simulation is left out of the emulator training set in turn. The emulator is trained with this reduced set, and a prediction is made for the omitted simulation. The relative error between the prediction and true output from the omitted simulation is then used as the leave-one-out score.
The distribution of relative errors from this calculation are shown for the flux power spectrum in Figure~\ref{fig:fps_error}.
These figures show the errors for a single-fidelity emulator that is predicting low fidelity outputs (grey), and the errors for a multi-fidelity emulator that is predicting high fidelity outputs (yellow). Note that because there are only three high fidelity simulations, the multi-fidelity emulator error distributions have much smaller sample sizes, and have been scaled for clarity.

In the left panels of Figures~\ref{fig:fps_error}, the absolute error normalized by the prediction uncertainty is shown.
For the distributions with large enough sample sizes, these appear to be normally distributed, as expected.
The right panels show the absolute relative error, a good indicator of the accuracy of the emulator predictions.
The flux power emulator has an average error of $0.7\%$, with a maximum of $8\%$, when predicting the low fidelity simulations. For the high fidelity predictions, the mean is similar, but the maximum leave-one-out interpolation error is smaller, $4\%$, reflecting the smaller test set. Note that because these are interpolation errors on a subset of the data, they are larger than the errors in the full multi-fidelity emulator.

For comparison, the flux power spectrum from BOSS DR14 \cite{Chabanier:2019}, which is dominated by systematics, has a diagonal error between $1.5\%$ (at $z=2.8$ and k = $5\times 10^{-3}$ s/km) and $\sim 15\%$ (at $z=4.6$). Our emulator error is thus in most of parameter space smaller than the observational systematics.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/fpsemu_errors.pdf}
    \caption{\label{fig:fps_error}
    Leave-one-out errors for the \Lya forest flux power spectrum emulator.
    The left panel shows the absolute error in units of prediction uncertainty.
    The right panel shows the relative errors, an estimate of how well the emulator predicts the flux power spectrum.
    The distributions show the prediction error for each redshift of each flux power sample included in the final training sample.
    The grey distribution shows the emulator error for a single-fidelity emulator, predicting the flux power for the LF simulations.
    The yellow distribution shows the errors for a multi-fidelity emulator, predicting the flux power for the HF simulations.
    }
\end{figure}

Ref.~\cite{Fernandez:2022} achieved sub-$1\%$ accuracy using $30$ low fidelity and $5$ high fidelity simulations. We have achieved similar accuracy with only $3$ high fidelity simulations. Our low fidelity training set has a mean inter-particle spacing of $78$ kpc/h, whereas Ref.~\cite{Fernandez:2022} use low fidelity simulations with a mean inter-particle spacing of $117$ kpc/h, and this accounts for the improvement.

%Emulator construction - kernel hyperparameters/ARD don't make much difference.
%LOO errors.

\section{Results}

\subsection{Box Size and Particle Load}
\label{sec:boxsize}

\begin{figure*}
\includegraphics[width=0.95\textwidth,trim={0 5cm 1cm 0},clip]{figures/box-convergence.pdf}
 \caption{Convergence of the flux power spectrum with box size. Shown is the ratio of the flux power spectrum as a function of redshift in a $120$ Mpc/h box compared to a $60$ Mpc/h box. Our primary simulations use a $120$ Mpc/h box. This is thus an upper limit on the convergence with respect to the simulation box. The range of $k$ measured by eBOSS is $10^{-3}$ s/km to $2\times 10^{-2}$ s/km. Other redshift bins are similar.}
 \label{fig:boxsize}
\end{figure*}

Figure~\ref{fig:boxsize} shows the effect of the finite box size on the flux power spectrum, as a function of redshift. We show the flux power spectrum ratio between a test simulation in a $60$ Mpc/h simulation box and a larger $120$ Mpc/h simulation box. The mean inter-particle spacing is $120$ kpc/h for both simulations, so that the large box simulation has $1024^3$ particles, while the small box simulation has $512^3$ particles. Since our main simulations use $120$ Mpc/h simulation boxes, this is an upper limit on the effect of the finite box. The non-linear scale at $z=2$ is $\sim 45 - 60$ Mpc/h.
%However, the \Lya~forest is predominantly sensitive to gas from $1-10$ times the mean density, and so the effect of non-linearities is reduced.

Cosmic variance is suppressed when compared to emulators of the matter power spectrum as our summary statistic is the $1$-D flux power spectrum, evaluated along the line of sight to the quasar and averaged over multiple quasar positions. Effectively this sums over two dimensions of the box, ensuring that even the largest scales sample Fourier modes proportional to the number of spectra. Since the larger box contains $8\times$ volume of the small box, Figure~\ref{fig:boxsize} is also a demonstration of the small effect of cosmic variance.

\begin{figure*}
\includegraphics[width=0.95\textwidth,trim={0 0 1cm 0},clip]{figures/resolution-convergence.pdf}
 \caption{Convergence of the flux power spectrum with resolution (mean interparticle spacing). The simulations are run with the same box size but different particle loads. The lines labelled $78$ kpc/h (blue solid) compares two simulations in a $120$ Mpc/h box. The first has $1536^3$ particles, and thus a mean-interparticle spacing of $78$ kpc/h, while the second has $3072^3$ particles. The lines labelled $39$ kpc/h compare two simulations in a $15$ Mpc/h box. The first has $384^3$ particles, and the second has $512^3$ particles.}
 \label{fig:resolution}
\end{figure*}

Figure~\ref{fig:resolution} shows the effect of finite resolution on our flux power spectrum predictions. We show in blue the difference between the high and low resolution branches of the emulator, for the $3$ different parameter sets. Our lower resolution simulations contain $2\times 1536^3$ particles in a $120$ Mpc/h periodic box with a mean inter-particle spacing of $79$ kpc/h. Our $3$ higher resolution simulations contain $2\times 3072^3$ particles and thus a mean inter-particle spacing of $39$ kpc/h. Figure~\ref{fig:resolution} shows that our high fidelity node is meaningfully correcting the resolution of our low fidelity simulations. The dependence of the resolution correction on cosmological parameters is fairly small, which explains why our multi-fidelity emulator can converge with only $3$ high fidelity simulations, compared to $6$ required in \cite{Fernandez:2022}. The prediction in this case is dominated by the cosmology-independent scaling factor $\rho$ in Eq.~\ref{eq:ko_model}.

The low fidelity node of the emulator constructed in \cite{Fernandez:2022} had a mean interparticle spacing of $118$ kpc/h, $1.5 \times$ the resolution we achieve here\footnote{We originally intended this to be the resolution of the low resolution node of our current emulator, but improvements in our simulation code between the two papers allowed us to increase our minimum particle load.}. The convergence in our low fidelity node is thus already reasonably good, at the level of $5\%$ for $k < 0.02$ s/km, the scales measured by eBOSS and $10\%$ for $k < 0.05$ s/km, which covers the scales expected to be measured by DESI. Note that these simulations have been rescaled to have the same mean optical depth, as these are the values input into the emulator.

To demonstrate convergence of our high fidelity node we also show a comparison between two $15$ Mpc/h box size simulations, one $384^3$ particles and thus the same resolution as our high fidelity node, and one with $512^3$ particles. Convergence is at the $2\%$ level for $z > 2.6$ and the sub-percent level for $z \leq 2.6$, apart from scales greater than $1/4$ the box size. This level of resolution sensitivity is small compared to current observational uncertainties.
The worst convergence is seen during helium reionization, which starts at $z=4$ and ends at $z=3.1$. This may indicate that the simulation is being affected by the small separation between the size of the box and the size of the helium reionizing bubbles, and that a hypothetical simulation in a larger box would display even better resolution convergence.

The scales measured by high resolution \Lya~forest spectra (XQ-100 and HIRES/MIKE) are $ k < 0.7$ s/km \cite{Irsic:2017}, which also marks the rough limit of the $2\%$ convergence for our high fidelity simulations (note the statistical error is $\sim 10\%$ for these scales). Our simulations are thus comparable to high resolution data, which we will address in future work.

It is interesting to compare our results to earlier simulation suites. Ref.~\cite{Borde:2014} performed a convergence study using a $20$ Mpc/h box and $192^3$ - $1024^3$ particles. Our high fidelity node is equivalent in resolution to their $20, 512^3$ simulation, and exhibits similar convergence for $z < 3.6$, although our simulations are fully hydrodynamic while theirs make use of the simplified \Lya~forest star formation model. However, at $z=4.4$, their simulation loses $2-5\%$ of the flux power for $k > 0.01$ s/km. Although this degree of convergence is negligible compared to the observational errors at $z=4.4$, we do not observe a similar effect.
We also found that our convergence at $z \sim 5$ was better than predicted by Ref.~\cite{2009MNRAS.398L..26B, Bolton:2017}. This is due to our inclusion of a temperature boost during hydrogen reionization \cite{DAloisio:2019}. We found that small test simulations without this boost had high redshift convergence behaviour similar to earlier work. The temperature boost heats the gas, increasing the thermal free-streaming length and Jeans' mass. This prevents small overdensities, which would normally be underresolved, from accreting gas.

%Describe the resolution and box size of the simulation. Justify this by citing the relevant 2014 paper and with the figure.
%\spb{Note that the convergence at high redshift is a little better than Bolton and Becker 2010, because the heating effect of the ionization fronts smooths the high redshift gas and prevents the small unresolved halos from accreting anyway.}


\subsection{Thermal Histories}

\begin{figure*}
\includegraphics[width=0.45\textwidth]{figures/mean-temperature.pdf}
\includegraphics[width=0.45\textwidth]{figures/mean-temperature-resolution.pdf}
 \caption{(Left) Temperatures at mean density as a function of redshift for simulations in our emulator. Observational points shown are the combined $T_0$ measurements from \protect\cite{Gaikwad:2021}.  The grey band shows the range of temperatures realised by simulations in our emulator. The black line shows an example thermal history, for a simulation with reionization parameters $\alpha_q = 1.80$, $z_{Hei} = 3.79$, $z_{Hef} = 3.09$, $z_{Hi} = 7.08$. Other parameters are $n_P = 0.823$, $A_P = 1.92 \times 10^{-9}$, $\Omega_0 h^2 = 0.1445$, $h = 0.69$, $\epsilon_{AGN} = 0.067$.
 %[8.22750000e-01 1.92333333e-09 3.79000000e+00 3.09000000e+00
 %1.79500000e+00 6.85000000e-01 1.44500000e-01 7.07500000e+00
 %6.66666667e-02]
 (Right) Ratio between the IGM mean temperature in low resolution simulations to the high resolution simulations. Convergence is at the level of $1\%$ while the observational error on the temperature is $5-10\%$.
}
 \label{fig:meanigmtempdens}
\end{figure*}

Figure~\ref{fig:meanigmtempdens} shows the mean temperatures for our simulations, confirming that our reionization models are able to bracket the observed mean IGM temperatures from Ref.~\cite{Gaikwad:2021}. The right panel shows the convergence with resolution, for our three high fidelity simulations, labelled by their $n_P$ values. Convergence is better than $3\%$ between the low and high fidelity simulations, showing that even our low fidelity nodes contain converged thermal histories. We have determined the IGM mean temperature thermal history Note that the thermal history is measured by comparing simulations to observed statistics of high resolution quasar spectra, such as the flux power spectrum on scales $0.01$ - $0.1$ s/km. These simulations did not use a patchy helium reionization model; however, given the relatively large observational error bars on the mean IGM temperature, this should not have a significant effect on our results. In future work we will directly carry out a comparison to these statistics, rather than using the derived thermal history. The high fidelity simulations generally have slightly lower temperature than the low fidelity simulations, as the inclusion of higher density structures increases the amount by which gas can cool. The high fidelity simulation labelled with $n_P=0.914$ has the lowest redshift of hydrogen reionization and lowest $\alpha_q$ and thus the strongest heating during helium reionization. The extra heating reduces the amount of dense gas and thus improves the overall convergence of the simulation.

%Ref.~\cite{Chabanier:2022} showed that SPH and grid codes agree to less than $1\%$.

\subsection{Effect of Parameters on the Flux Power Spectrum and Temperature}
\label{sec:singleparams}

\begin{figure}
    \centering
    \includegraphics[width=0.48\columnwidth]{figures/single_param_tau0.pdf}
    \includegraphics[width=0.48\columnwidth]{figures/single_param_dtau0.pdf}
	\includegraphics[width=0.48\columnwidth]{figures/single_param_Ap.pdf}
		\includegraphics[width=0.48\columnwidth]{figures/single_param_ns.pdf} \\
    \includegraphics[width=0.48\columnwidth]{figures/single_param_omegamh2.pdf}
    	\includegraphics[width=0.48\columnwidth]{figures/single_param_hub.pdf}
    \caption{Predicted effect on the flux power spectra from the full multi-fidelity emulator when changing a single simulation parameter, for three representative redshifts. All other parameters are shown fixed to the midpoint of their range. The top row shows the mean flux model parameters $\tau_0$(Top-Left) and $d\tau_0$ (Top-Right). The other rows show the cosmological parameters $A_p$ (Mid-Left) and $n_P$ (Mid-Right), $\Omega_m h^2$ (Bottom-Left) and $h$ (Bottom-Right). }
    \label{fig:Apnsfluxpower}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.48\columnwidth]{figures/single_param_t0_hi_.pdf}
    \includegraphics[width=0.48\columnwidth]{figures/single_param_t0_hef_.pdf} \\
    \caption{Effect on the mean IGM temperature $T_0$ as a function of redshift, for the four reionization parameters which significantly change $T_0$. (Top-Left) Effect of $z_\mathrm{Hei}$ and $z_\mathrm{HI}$. (Top-Right) Effect of $z_\mathrm{Hef}$ and $\alpha_q$.}
    \label{fig:meantempfluxpower}
\end{figure}

\begin{figure}
    \centering
	\includegraphics[width=0.48\columnwidth]{figures/single_param_herei.pdf}
    \includegraphics[width=0.48\columnwidth]{figures/single_param_heref.pdf} \\
	\includegraphics[width=0.48\columnwidth]{figures/single_param_hireionz.pdf}
    \includegraphics[width=0.48\columnwidth]{figures/single_param_alphaq.pdf}
    \caption{Predicted effect on the flux power spectra from the full multi-fidelity emulator when changing a single simulation parameter, for three representative redshifts. All other parameters are shown fixed to the midpoint of their range. Shown are the four reionization parameters $z_\mathrm{Hei}$ (Top-Left) and $z_\mathrm{Hef}$ (Top-Right), $z_\mathrm{HI}$ (Bottom-Left) and $\alpha_q$ (Bottom-Right).}
    \label{fig:zhefluxpower}
\end{figure}

In this Section we discuss the effect of varying each parameter individually on the flux power spectrum, as predicted by our multi-fidelity emulator. We can use this to understand which parameters are most strongly measured by the \Lya~forest, and where the strongest degeneracies lie. Figure~\ref{fig:Apnsfluxpower} shows the mean flux and cosmological parameters. The top row shows the mean flux rescaling parameters $\tau_0$ and d$\tau_0$, which control the total abundance of neutral hydrogen as a function of redshift. As a reminder, these parameters are defined so that  $\tau_0 = 1$ and d$\tau_0 = 0$ correspond to $\tau_\mathrm{eff} = 0.0023 (1+z)^{3.65}$. The mean flux controls the amplitude of the flux power spectrum, and has an effect analogous to the linear bias parameter of galaxy surveys. A good order of magnitude model is that the amplitude of the flux power spectrum is directly proportional to $\tau_0$, with increased sensitivity at high redshift where the overall absorption is larger. Note that, by construction, the effect of d$\tau_0$ at $z=3$ is zero.

Importantly, because the mean flux parameter must be constrained first and is measured by thr amplitude of the flux power spectrum, the \Lya~forest measures other cosmological parameters only insofar as they change the power spectrum shape. The initial power spectrum  amplitude $A_P$, shown in the middle row of Figure~\ref{fig:Apnsfluxpower} also changes the flux power spectrum amplitude. However, it is not degenerate with the mean flux. Increasing $A_P$ increases the flux power spectrum amplitude only on large scales, with small scales partially washed out by nonlinear growth. The spectral index $n_P$ (right panel of middle row) changes the slope of both the initial matter power spectrum and the flux power spectrum, but again is partially washed out on small scales for $z < 3$.

The above four parameters dominate the information content of the flux power spectrum on these scales \cite{Pedersen:2022}. The other two cosmological parameters are the growth function $\Omega_M h^2$ and $h$, whose effect on the flux power spectrum is significantly smaller. As expected, for constant $\Omega_M h^2$, changing $h$ also changes $\Omega_M$ and thus slightly shifts the mapping between physical and velocity units (the shift is slight because at $z=2$ we are deep in the matter dominated era). The small, poorly correlated, change in the flux power spectrum is due mostly to modes shifting between bins and thus dominated by the small residual effect of cosmic variance. The growth function $\Omega_M h^2$ does change the amplitude of the flux power spectrum. The effect is similar to $A_P$ in shape, but distinguished from it by a much stronger dependence on redshift. Lower redshifts have experienced more growth and are thus more sensitive to the growth function. The overall amplitude of the change in the flux power spectrum is smaller than $A_P$, as this parameter is already fairly well constrained by Planck \cite{Planck:2018}, and so our emulator limits are relatively tight compared to the constraints available from the \Lya~forest alone.

Figure~\ref{fig:meanigmtempdens} shows the effect of the thermal parameters on the mean IGM temperature. A later hydrogen reionization redshift gives the gas less time to cool after the temperature boost and thus increases the temperature of the IGM moderately, although the effect is washed out once helium reionization starts. The effect of the onset of helium reionization is large during the initial phases of helium reionization, but quickly diminishes by $z=3.0$. The sign of the effect is reversed at lower redshift: a later starting point of helium reionization leads to a higher final temperature as reionization proceeds faster and the gas experiences less cooling during the reionization process. The quasar spectral index $\alpha_q$ directly controls the temperature during reionization: a lower $\alpha_q$ leads to a higher peak temperature, while a higher $\alpha_q$ leads to a lower temperature. After reionization finishes, the cooling rate is the same irrespective of the peak temperature, so reducing $\alpha_q$ still boosts the temperature at $z=2.2$. During helium reionization, the effect of  $z_\mathrm{Hef}$ is similar to $\alpha_q$. A shorter helium reionization means the gas is heated more strongly while reionization is ongoing. However, once helium reionization has finished the effect is much smaller. As with $z_\mathrm{Hei}$, a shorter duration of helium reionization leads to a higher final temperature as the gas experiences has less time to cool.

Figure~\ref{fig:zhefluxpower} shows the effect of the thermal parameters on the flux power spectrum. Changing the gas temperature changes the neutral fraction and thus the amplitude of the flux power spectrum. This is not completely degenerate with the mean optical depth parameters as the redshift dependence is proportional to the way each parameter affects the IGM temperature, shown in Figure~\ref{fig:meanigmtempdens}. Thus the amplitude shifts are largest during helium reionization and smaller by $z=2.2$. However, since $z_\mathrm{Hei}$, $z_\mathrm{Hef}$ and $\alpha_q$ all affect the flux power spectrum amplitude in similar ways, constraints on the thermal history from the flux power spectrum alone are likely to suffer from a three way degeneracy. The best constraints will continue to come from scales which resolve the thermal cutoff in the power spectrum \cite{Gaikwad:2021}. On large scales there is a scale-dependent effect visible when changing $z_{Hef}$ and $\alpha_q$. A scale-dependent bias signature is expected from patchy helium reionization, as discussed in Refs.~\cite{Pontzen:2014a, Pontzen:2014b,  Gontcho:2014}. Essentially, different regions of the box have different temperatures, depending on when they reionized. This effect is only present on the largest scales probed by BOSS (and is mostly degenerate with the effect of DLA damping wings \cite{Rogers:2017}), so it is likely not directly measurable in the 1D flux power spectrum. In future work we will look at measuring this bias using 3D correlations.

At $z=4.4$, for a low hydrogen reionization midpoint, the emulator predicts a similar large-scale effect from our patchy hydrogen reionization model. This would not yet be detectable in BOSS data as the statistical error at this redshift is still large compared to the effect, however it may be detectable in DESI. By $z=3.2$, the effect of the hydrogen reionization midpoint has mostly disappeared. A similar effect was examined in \cite{Molaro:2022} using radiative transfer simulations, where they showed explicitly that the statistical power of high resolution \Lya~forest spectra is not yet sufficient to observe this effect.

\subsubsection{Effect of AGN Feedback Strength}

\begin{figure*}
\centering
\includegraphics[width=0.48\columnwidth]{figures/single_param_bhfeedback.pdf}
\includegraphics[width=0.48\textwidth]{figures/cddf_hires.pdf}
 \caption{(Left) Predicted effect on the flux power spectra from the full multi-fidelity emulator when changing the strength of black hole feedback, $\epsilon_\mathrm{AGN}$ for three representative redshifts. All other parameters are shown fixed to the midpoint of their range. (Right) Column density distribution function (CDDF) of high column density absorbers from our $3$ high resolution simulations at $z=2.2$, compared to SDSS DR16 \cite{2021MNRAS.507..704H}.}
 \label{fig:DLACDDF}
\end{figure*}

Ref.~\cite{Viel:2013} showed an effect of AGN feedback which rises to $10\%$ at $z=2$, while Ref.~\cite{Chabanier:2020} found $8\%$ at $z=2$ and $k = 0.005$ s/km. Both simulations use AGN feedback models with parameters tuned to match the properties of galaxies at $z=0$. However, the implementations are different. Ref.~\cite{Chabanier:2020} uses the Horizon-AGN simulation \cite{Dubois:2016}. The AGN feedback model has two modes, one thermal and one kinetic, with the kinetic mode dominating at low accretion rates. Ref.~\cite{Viel:2013} uses the OWLS simulation suite, and delivers AGN feedback energy thermally, once black hole accretion has accumulated enough energy to heat a nearby gas particle to $10^8$ K. Despite the different implementations, the two codes agree reasonably well as to the effect of AGN feedback on the \Lya~forest.

Figure~\ref{fig:DLACDDF} shows the effect of varying our AGN feedback parameter on the 1D flux power spectrum from our emulator. This effect is extremely small, $<1\%$ on the BOSS scales, and shows no clear dependence on redshift or scale. Note that this result is not necessarily in disagreement with the results of \cite{Viel:2013, Chabanier:2020} as these show a 10\% effect when including or removing AGN feedback. Since all our simulations include AGN feedback we cannot estimate this effect. Figure~\ref{fig:DLACDDF} shows instead the effect on the flux power spectrum of a moderate variation in the strength of our AGN feedback model.
%Although the instantaneous strength of the feedback model varies by a factor of two, the impact on the overall star formation history of the box is smaller, as weaker AGN feedback leads to more star formation feedback.
In retrospect it would have been sufficient to fix the AGN feedback strength to the default instead of varying it in our emulator. We did not because an initial test using a suite of $20$ Mpc/h small box simulations showed a more substantial effect. This turned out to be due to sample variance: a small box contains a small number of large mass halos hosting AGN, and the time at which each of them heats the gas is strongly affected by the strength of the AGN feedback parameter. In a larger box these differences average out.

%There was also a correlation with cosmology because changing the cosmology changed the number of AGN-hosting halos.

Our simulations do not enable the ASTRID kinetic black hole feedback model \cite{Ni:2023}. Kinetic feedback was implemented for the Illustris-TNG simulation by \cite{Weinberger:2017}. Black holes in a low accretion state (as measured by a fraction of the Eddington rate) and with a mass above $M_\mathrm{BH, pivot} = 10^8 M_\odot/h$ produce a strong kinetic wind that drives gas outflows from a host galaxy cluster and so allows the simulation to match the observed cluster baryon fraction. Compared to Illustris-TNG, ASTRID uses a higher black hole mass threshold of $M_\mathrm{BH, pivot} = 5\times 10^8 M_\odot/h$ and a somewhat more stringent accretion rate threshold, making it more mild in its effects on the global gas distribution.

Our three high fidelity simulations contain $0, 1$ and $16$ black holes with masses over $5\times 10^8 M_\odot/h$ at $z=2.2$, suggesting that the potential effect of kinetic feedback on our simulations is extremely small. Considering a lower mass threshold of $10^8 M_\odot/h$, we have $5, 7, 62$ black holes. The maximum radius at which kinetic feedback could affect the gas is $\sim 1$ Mpc. Thus, even in the most generous formulation it is unlikely that kinetic feedback could affect more than $10^{-4}$ of our simulation volume. It is, of course, possible that other models of AGN feedback could be created that are stronger at high redshift. The AGN feedback model used in the SIMBA simulations \cite{SIMBA} is substantially stronger than the one in Illustris-TNG \cite{Tillman:2022}. However, at $z=2$ it also has fairly minimal impact on the matter power spectrum \cite{CAMELS}, suggesting again a small effect on the $z=2$ \Lya~forest.

\subsection{High Column Density Systems}

Figure~\ref{fig:DLACDDF} shows the predicted column density distribution function for high column density absorbers from our three high fidelity simulations. We have generated spectra at random positions until we have $4000$ spectra, each containing a system with column density $N_{HI} > 10^{18}$ cm$^{-2}$. There is good agreement between the simulations and the observed CDDF from Ref.~\cite{2021MNRAS.507..704H}. This can be taken as a strong prior on the supernova wind parameters and justifies our choice to fix the wind model in our emulator. Furthermore, there is no strong or consistent variation with emulator parameters, which reinforces that the cosmological information in the high column density absorbers is small and so it is optimal to exclude them when computing the flux power spectrum.

\section{Conclusions}

We present a new, large, suite of cosmological simulations aimed at simulating the \Lya~forest. We have used the multi-fidelity technique from \cite{Ho:2022, Fernandez:2022} to combine simulations at different resolutions, and build a cosmological emulator covering the parameter space spanned by the simulations. We include two cosmological parameters, the spectral slope $n_s$ and the perturbation amplitude $A_P$. We also vary $h$ and the growth factor $\Omega_M h^2$. These last two have a relatively small effect on the \Lya~forest on these scales, but we include them to ensure that the uncertainty resulting from them can be properly marginalised over. We include astrophysical parameters for changes in the mean flux (in post-processing), for the strength of AGN feedback, the start and end redshifts of helium reionization, as well as the resulting temperature boost, and the redshift of hydrogen reionization.

Our simulations are some of the largest ever performed in a latin hypercube suite. We have a $120$ Mpc/h box, enough for a fair cosmological sample with minimal cosmic variance at $z=2$ and a softening length of roughly kpc, comparable to other galaxy formation simulations. Note that our highest resolution simulations have a moderately higher resolution than, for example, the Illustris \cite{Vogelsberger:2014} or ASTRID \cite{Bird:2022, Ni:2021} simulations. We have performed $48$ low resolution simulations and $3$ high resolution simulations, which is sufficient to reduce emulation error to the percent-level, as demonstrated by our leave-one-out analysis. We have shown the predicted single-parameter variations in the 1D flux power spectrum for each cosmological and astrophysical parameter, and shown that these agree with physical expectations or literature predictions.

In a companion work, we have developed a likelihood function to compare the predictions from our emulator to the 1D flux power spectrum from BOSS. In that work we will use the likelihood function to place posterior constraints on cosmological parameters using this existing dataset. In addition, the likelihood function is prepared for evaluating future datasets.

Much of the new information in future surveys will come from statistics other than the 1D flux power spectrum. The correlation function between quasars was measured by Ref.~\cite{Slosar:2011}, and has been used to detect the baryon acoustic oscillation (BAO) feature and thus constrain the expansion rate at $z\sim 2.3$ \cite{dSAgathe:2019, Cuceu:2022}. Concurrently, \Lya~tomography surveys with a high sightline density have allowed mapping coherent Mpc-scale overdensities \cite{Lee:CLAMATO, LATIS, Qezlou:2022}. In future work we will use the simulation suite and spectra presented here for comparisons to these other summary statistics.

\section*{Acknowledgements}
MAF is supported by a National Science Foundation Graduate Research Fellowship under grant No. DGE-1326120.
MFH is supported by a National Aeronautics and Space Administration FINESST under grant No. ASTRO20-0022.
SB is supported by NSF grant AST-1817256 and NASA-80NSSC21K1840.

Computing resources were provided by Frontera LRAC AST21005.
The authors acknowledge the Frontera computing project at the Texas Advanced Computing Center (TACC) for providing HPC and storage resources that have contributed to the research results reported within this paper.
Frontera is made possible by National Science Foundation award OAC-1818253.
URL: \url{http://www.tacc.utexas.edu}

\section*{Data Availability}
Flux power spectra generated from the low resolution, high resolution, and testing sets are available at.
Both HDF5 and plain text (appropriate for multi-fidelity emulation) formats are available.
Single- and multi-fidelity emulator predictions for the $10$ testing simulations are also available from the same repository.
The spectra underlying the flux power are available upon request.
\spb{We should try to make the spectra and flux power available for this one, but only after the likelihood paper is written.}

\bibliographystyle{JHEP}
\bibliography{refs}

\appendix

\label{lastpage}
\end{document}
